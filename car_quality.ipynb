{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2oBnQfTTyYQlyfFj1yTJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iris2311/car-quality/blob/encoding/car_quality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will import libraries we will use through this project."
      ],
      "metadata": {
        "id": "5DxCwo7vM5De"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n",
        "!pip install ucimlrepo\n",
        "import numpy\n",
        "import matplotlib.pyplot\n",
        "import pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL35wlW1ON-J",
        "outputId": "4d22be50-512e-4196-960c-1c751b88d21e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "                                        #this code was found on the same page where the dataset\n",
        "car_evaluation = fetch_ucirepo(id=19)    #database\n",
        "\n",
        "X = car_evaluation.data.features         #X features\n",
        "y = car_evaluation.data.targets          #Y feature\n",
        "\n",
        "print(car_evaluation.metadata)\n",
        "\n",
        "print(car_evaluation.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PElDJhngPtc1",
        "outputId": "4bb3e25c-2444-4527-fe19-cbfcc3b6e5c6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 19, 'name': 'Car Evaluation', 'repository_url': 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'data_url': 'https://archive.ics.uci.edu/static/public/19/data.csv', 'abstract': 'Derived from simple hierarchical decision model, this database may be useful for testing constructive induction and structure discovery methods.', 'area': 'Other', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 1728, 'num_features': 6, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5JP48', 'creators': ['Marko Bohanec'], 'intro_paper': {'title': 'Knowledge acquisition and explanation for multi-attribute decision making', 'authors': 'M. Bohanec, V. Rajkoviƒç', 'published_in': '8th Intl Workshop on Expert Systems and their Applications, Avignon, France', 'year': 1988, 'url': 'https://www.semanticscholar.org/paper/KNOWLEDGE-ACQUISITION-AND-EXPLANATION-FOR-DECISION-Bohanec-Rajkovi%C4%8D/8bab443ae322ff47c3e609272bd93fd4650555bc', 'doi': None}, 'additional_info': {'summary': 'Car Evaluation Database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX, M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.). The model evaluates cars according to the following concept structure:\\r\\n\\r\\nCAR                      car acceptability\\r\\n. PRICE                  overall price\\r\\n. . buying               buying price\\r\\n. . maint                price of the maintenance\\r\\n. TECH                   technical characteristics\\r\\n. . COMFORT              comfort\\r\\n. . . doors              number of doors\\r\\n. . . persons            capacity in terms of persons to carry\\r\\n. . . lug_boot           the size of luggage boot\\r\\n. . safety               estimated safety of the car\\r\\n\\r\\nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for these examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\\r\\n\\r\\nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety.\\r\\n\\r\\nBecause of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\\r\\n', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'buying:   vhigh, high, med, low.\\nmaint:    vhigh, high, med, low.\\ndoors:    2, 3, 4, 5more.\\npersons:  2, 4, more.\\nlug_boot: small, med, big.\\nsafety:   low, med, high.', 'citation': None}}\n",
            "       name     role         type demographic  \\\n",
            "0    buying  Feature  Categorical        None   \n",
            "1     maint  Feature  Categorical        None   \n",
            "2     doors  Feature  Categorical        None   \n",
            "3   persons  Feature  Categorical        None   \n",
            "4  lug_boot  Feature  Categorical        None   \n",
            "5    safety  Feature  Categorical        None   \n",
            "6     class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                       buying price  None             no  \n",
            "1                           price of the maintenance  None             no  \n",
            "2                                    number of doors  None             no  \n",
            "3              capacity in terms of persons to carry  None             no  \n",
            "4                           the size of luggage boot  None             no  \n",
            "5                        estimated safety of the car  None             no  \n",
            "6  evaulation level (unacceptable, acceptable, go...  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the code output above, we can see that all variables are categorical and there is no missing values. In this project we will split data into train set (80%) and test set (20%) by using function from sklearn library.\n"
      ],
      "metadata": {
        "id": "aFh74PedM6qW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree algorithm works with numerical data, so we need to encode categorical variables which represents car quality. It is important that we do that before spliting the data into train and test set."
      ],
      "metadata": {
        "id": "RWCV2KxRWP7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "x_transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety'] )])\n",
        "y_transformer = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])])\n",
        "X=x_transformer.fit_transform(X).toarray()\n",
        "y=y_transformer.fit_transform(y).toarray()\n",
        "\n",
        "\n",
        "#attributes of ColumnTransformer: first element of transformers is type of transformation\n",
        "#second is type of encoding\n",
        "#third is columns on which the transformation is made"
      ],
      "metadata": {
        "id": "adLZcAFrWiy2"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train and Y_train is the train set\n",
        "#X_test and Y_test is the test set\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size=0.2, random_state=1)    #test size is 0.2 because test set size is 20%\n",
        "                                                                                          #random state=1 means data will be shuffled"
      ],
      "metadata": {
        "id": "XN4Xo6ItRPNJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing train set:"
      ],
      "metadata": {
        "id": "zpp_DYv2SxJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)\n",
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-dYWxqTSerU",
        "outputId": "5b19bd37-e530-4cb5-de04-51acaa03e75d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 1. 0. 0.]]\n",
            "[[0. 1. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing test set:"
      ],
      "metadata": {
        "id": "t_VormhhS-z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)\n",
        "print(Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju0QiMqOTA_7",
        "outputId": "aae8e063-6341-4827-af0f-dfb3b88a7566"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. ... 0. 1. 0.]\n",
            " [1. 0. 0. ... 0. 0. 1.]\n",
            " [1. 0. 0. ... 0. 0. 1.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 1.]]\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because there is no missing data, this is the end of the data preprocessing phase. Decision trees and random forests are not sensitive to feature scaling because their splits don‚Äôt change with any monotonic transformation, so we don't need to apply feature scaling.   (https://forecastegy.com/posts/do-decision-trees-need-feature-scaling-or-normalization/)"
      ],
      "metadata": {
        "id": "uMaE4hSOTOLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier     #Decision tree is already implemented in the sklearn library\n",
        "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
        "                                                      #criterion is function to measure the quality of a split\n",
        "\n",
        "classifier.fit(X_train, Y_train)  #we have to train our model on the train set data"
      ],
      "metadata": {
        "id": "0-alFy6vUtba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}